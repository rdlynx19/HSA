env:
  xml_file: "hsaModel.xml"
  n_envs: 4
  frame_skip: 20
  actuator_group: [1]
  action_group: [1]
  # === REWARD STRUCTURE ===
  # Forward progress (main objective)
  forward_reward_weight: 10.0

  # Efficiency costs (minor - encourage good behaviour)
  ctrl_cost_weight: 0.001
  contact_cost_weight: 0.005
  acc_cost_weight: 0.00001

  # Direction costs (moderate - enforce straight movement)
  yvel_cost_weight: 4.0

  # Constraint cost (important - enforce mechanical limits)
  constraint_cost_weight: 0.1

  # Stability/survival (critical - prevent early termination)
  alive_bonus: 0.4 # (reward for staying alive each step)
  early_termination_penalty: 50.0  # (big penalty for falling/failing)
  smooth_positions: true
  max_increment: 0.785
  max_episode_steps: 2000

model:
  policy: "MlpPolicy"
  n_steps: 2048
  batch_size: 64
  learning_rate: 0.0003
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.01

train:
  total_timesteps: 40_000_000
  log_dir: "./logs/"
  run_name: "ppo_velocity"
  checkpoint_dir: "./checkpoints/"
  checkpoint_freq: 500_000
  resume: false
  